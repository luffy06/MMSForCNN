# 针对CNN的任务调度算法

# 问题
1. 执行时间
我发现funll-count-dense-model里，LCTES的结果比BASELINE还要差，为什么？
2. Prelogue
我们的算法里，随着CORE数量的变化，PRELOGUE的长度变化的趋势是不一致的。
例如，leNet 里，是增加然后不动的，32CORE最小，64,128,256是一样的结果
而cnn-sentence-classif里，是两边大，中间小的，32CORE和256CORE最大，64和128CORE的小
而VGG-E里，是逐级递减的，32CORE最大，256CORE最小
为什么会出现趋势不一致的情况？
3. 还是Prelogue
为什么LCTES 32core的情况prelogue都是0？什么样的调度能让prelogue都是0？
4. Retiming
Retiming也存在趋势不一致的情况
5. 还是retiming
为什么我们的retiming都是上百，lctes的只有1或者2?
6. loop kernel
最好把loop kernel的执行时间列出来。现在看来好像我们的loop kernel要比LCTES短很多很多
7.利用率
还是老问题：真是无法理解为什么baseline的利用率会低到那么可怜？只有1%？
LCTES也有部分的利用率极其低
8. 还是利用率
还是老问题：不清楚为什么我们方法的利用率随着CORE的增加而减小？
